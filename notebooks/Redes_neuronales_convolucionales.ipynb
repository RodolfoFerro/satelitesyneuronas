{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMK0jbPFXRouf3F9WL4yFHR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodolfoFerro/satelitesyneuronas/blob/main/notebooks/Redes_neuronales_convolucionales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redes neuronales convolucionales"
      ],
      "metadata": {
        "id": "CssVPTfc8tPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Convoluciones en imágenes**\n",
        "\n",
        "Exploremos qué sucede cuando barremos un filtro (kernel) sobre una imagen utilizando una convolución.\n",
        "\n",
        "**Spoiler:** Intentemos escalar posibles resultados al tener muchos filtros dentro de una red neuronal."
      ],
      "metadata": {
        "id": "jJdHo17RAp4S"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kdal-XjznDC"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# We load a sample image\n",
        "img = datasets.ascent()\n",
        "\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos una copia de la imagen."
      ],
      "metadata": {
        "id": "Mbmr-R6Yyv36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_transformed = np.copy(img)\n",
        "size_x = img_transformed.shape[0]\n",
        "size_y = img_transformed.shape[1]"
      ],
      "metadata": {
        "id": "HNcuUIMjx_VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos un filtro a utilizar."
      ],
      "metadata": {
        "id": "2nqmKQ94yxX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's experiment with different values\n",
        "\n",
        "filter = [[1, 2, 1], [2, 4, 2], [1, 2, 1]]\n",
        "# filter = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
        "# filter = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
        "\n",
        "weight = 1 / 8"
      ],
      "metadata": {
        "id": "ckPpotCCyIKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos las operaciones."
      ],
      "metadata": {
        "id": "B_jvUdSOyy_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(1, size_x - 1):\n",
        "  for y in range(1, size_y - 1):\n",
        "      convolution = 0.0\n",
        "      convolution = convolution + (img[x - 1, y - 1] * filter[0][0])\n",
        "      convolution = convolution + (img[x, y - 1] * filter[0][1])\n",
        "      convolution = convolution + (img[x + 1, y - 1] * filter[0][2])\n",
        "      convolution = convolution + (img[x - 1, y] * filter[1][0])\n",
        "      convolution = convolution + (img[x, y] * filter[1][1])\n",
        "      convolution = convolution + (img[x + 1, y] * filter[1][2])\n",
        "      convolution = convolution + (img[x - 1, y + 1] * filter[2][0])\n",
        "      convolution = convolution + (img[x, y + 1] * filter[2][1])\n",
        "      convolution = convolution + (img[x + 1, y + 1] * filter[2][2])\n",
        "      convolution = convolution * weight\n",
        "\n",
        "      if convolution < 0:\n",
        "        convolution = 0\n",
        "      if convolution > 255:\n",
        "        convolution = 255\n",
        "\n",
        "      img_transformed[x, y] = convolution"
      ],
      "metadata": {
        "id": "4LQtpt51yKvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos los resultados de convolución."
      ],
      "metadata": {
        "id": "9W8I0UdWy1hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img_transformed, cmap='gray')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X4k5e1TnyM9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Pooling en imágenes**\n",
        "\n",
        "Exploremos qué sucede cuando reducimos la información de una imagen a través de pooling.\n"
      ],
      "metadata": {
        "id": "u_KzB9X-BYH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import skimage.measure\n",
        "\n",
        "\n",
        "img_transformed = np.copy(img)\n",
        "\n",
        "plt.imshow(img_transformed, cmap='gray')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QHbJKpQaBJD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "0HgJEJgOFN6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_transformed = skimage.measure.block_reduce(img_transformed, (2,2), np.max)\n",
        "\n",
        "plt.imshow(img_transformed, cmap='gray')\n",
        "plt.grid(False)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XVFt1epVBvew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_transformed.shape"
      ],
      "metadata": {
        "id": "THZUEY2LFRma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Redes neuronales convolucionales**\n",
        "\n",
        "**Spoiler:** Nuevamente, intentemos escalar posibles resultados al tener muchos filtros dentro de una red neuronal.\n",
        "\n",
        "Para ello, crearemos un modelo de red neuronal convolucional profunda, que utilice, precisamente, convoluciones en sus capas.\n",
        "\n",
        "Nos basaremos en un modelo LeNet5 propuesto por un gran investigador, Yann LeCun:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://www.datasciencecentral.com/wp-content/uploads/2021/10/1lvvWF48t7cyRWqct13eU0w.jpeg\" width=\"60%\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "WCO2eFvsCOVs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y__BooJ9LTL9"
      },
      "source": [
        "#### El dataset a utilizar: Trees in Satellite Imagery\n",
        "\n",
        "El dataset está compuesto por imágenes de 64x64 pixeles, que contienen un conjunto de 2 categorías.\n",
        "\n",
        "El dataset fue descargado de: https://www.kaggle.com/datasets/mcagriaksoy/trees-in-satellite-imagery\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/RodolfoFerro/satelitesyneuronas/raw/refs/heads/main/assets/data/trees.zip\n",
        "!unzip trees\n",
        "!mv Trees\\ in\\ Satellite\\ Imagery trees_dataset"
      ],
      "metadata": {
        "id": "WEV21IJJvqEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "s8b_JqUrmVmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "dataset_path = 'trees_dataset'\n",
        "classes = ['Trees', 'NoTrees']\n",
        "img_size = 64\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for label, class_name in enumerate(classes):\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "    for img_name in os.listdir(class_path):\n",
        "        img_path = os.path.join(class_path, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (img_size, img_size))\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(f\"Loaded {len(images)} images with shape {images.shape}\")\n",
        "print(f\"Loaded {len(labels)} labels with shape {labels.shape}\")"
      ],
      "metadata": {
        "id": "mFkKFButmXPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_images, testing_images, training_labels, testing_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training images shape: {training_images.shape}\")\n",
        "print(f\"Testing images shape: {testing_images.shape}\")\n",
        "print(f\"Training labels shape: {training_labels.shape}\")\n",
        "print(f\"Testing labels shape: {testing_labels.shape}\")"
      ],
      "metadata": {
        "id": "xAwDPH3NmYkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cómo se ven estos valores? Despleguemos una imagen de entrenamiento y una etiqueta de entrenamiento para saber."
      ],
      "metadata": {
        "id": "dfvbC_UewVZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.set_printoptions(linewidth=200)\n",
        "\n",
        "\n",
        "# Set index of image to be seen\n",
        "img_index = 0\n",
        "\n",
        "# Plot image\n",
        "plt.imshow(training_images[img_index], cmap='gray')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", training_labels[img_index])\n",
        "print(\"Matrix:\", training_images[img_index])"
      ],
      "metadata": {
        "id": "m8lf8r2IvvQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notarás que todos los valores están entre 0 y 255. Si estamos entrenando una red neuronal, por varias razones es más fácil si transformamos los valores para tratar todos con valores entre 0 y 1."
      ],
      "metadata": {
        "id": "iNlmvxJ7wagU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "DA7Oh9Kov3we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notemos que cada imagen es sólo una matriz de 28x28 pixeles, sólo con 1 canal de color."
      ],
      "metadata": {
        "id": "zURylVeHwpiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images[0].shape"
      ],
      "metadata": {
        "id": "wnwJemqkwoDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((64, 64, 3)),\n",
        "\n",
        "    # First conv layer + subsampling\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Second conv layer + subsampling\n",
        "    # TODO. Conv2D -> 256, (3, 3), ReLU\n",
        "    # TODO. MaxPool\n",
        "\n",
        "    # Third layer (flatten)\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Fourth layer (dense)\n",
        "    # TODO. Dense -> 128, ReLU\n",
        "\n",
        "    # Fifth layer (output)\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "stCt0xNzzk_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(\n",
        "    optimizer=tf.optimizers.SGD(),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "Q85XFofVzskY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.fit(training_images, training_labels, epochs=2)"
      ],
      "metadata": {
        "id": "ZwGZ6QBgz7Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "6Uxhd3HVz88g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "test_index = random.randint(0, 2080 - 1)\n",
        "\n",
        "plt.imshow(test_images[test_index], cmap='gray')\n",
        "plt.axis(False)\n",
        "\n",
        "print(\"Label:\", test_labels[test_index])\n",
        "input_image = np.reshape(test_images[test_index], (1, 28, 28, 3))\n",
        "prediction = cnn_model.predict(input_image)\n",
        "print(\"Prediction:\", np.argmax(prediction))"
      ],
      "metadata": {
        "id": "MXzIcx4Kz-b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reto:** ¿Puedes mejorar aún más el modelo?\n",
        "\n",
        "Te recomiendo explorar lo siguiente:\n",
        "- Modifica el número de capas y parámetros de convolución por capa\n",
        "- Modifica el número de épocas de entrenamiento\n",
        "- Explora resultados con otros conjuntos de datos\n",
        "- ¿Exportar modelos entrenados? Ojo: https://www.tensorflow.org/guide/keras/save_and_serialize?hl=es-419"
      ],
      "metadata": {
        "id": "8U1tdrMYlDen"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Para resolver la tarea, el reto es:** Mejor accuracy obtenido en la clase.\n",
        "\n",
        "**Puedes explorar:**\n",
        "- El número de capas.\n",
        "- Las épocas de entrenamiento.\n",
        "- Las funciones de activación.\n",
        "- Investigar otras capas."
      ],
      "metadata": {
        "id": "QKp_PZ_NDqbS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSdbQU3e6-Ky"
      },
      "source": [
        "---\n",
        "> Contenido creado por **Rodolfo Ferro**. Contacto: [ferro@cimat.mx](ferro@cimat.mx) <br>\n",
        "[**Clubes de Ciencia México**](https://clubesdeciencia.mx/), 2025."
      ]
    }
  ]
}